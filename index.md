---
layout: homepage
---

## About Me

I am a fourth-year Ph.D. candidate at the Institute for Interdisciplinary Information Sciences (IIIS), **Tsinghua University**, advised by Prof. [Hang Zhao](https://hangzhaomit.github.io/). Before that, I received my B.E. degree from **Peking University**.

My goal is to enable machines to perceive and interact with the physical world intelligently. To this end, my research bridges Computer Vision and End-to-End Learning, specifically within the contexts of **Embodied AI** and **Autonomous Driving**. Recently, I have been focusing on developing **Vision-Language-Action (VLA)** models and **World-Action models** to enhance robotic capabilities.

## Research Interests

- **Embodied AI:** VLA Models, World-Action Models
- **Autonomous Driving:** End-to-End Learning, Mapping

## News

- **[Jan. 2026]** Our paper [DepthVLA](https://arxiv.org/pdf/2510.13375.pdf) and [Galaxea Open-World Dataset](https://opengalaxea.github.io/GalaxeaVLA/) is accepted by ICRA 2026. 
- **[Jan. 2026]** We released [G0Plus](https://github.com/OpenGalaxea/GalaxeaVLA)., our latest pre-trained VLA model for multi-task robot manipulation.
- **[Sep. 2025]** We released Galaxea Open-World Dataset and G0 VLA on [Github](https://github.com/OpenGalaxea/GalaxeaVLA) and [Huggingface](https://huggingface.co/datasets/OpenGalaxea/Galaxea-Open-World-Dataset).
- **[Mar. 2025]** Our paper [LONG3R](https://arxiv.org/pdf/2507.18255.pdf) is accepted by ICCV 2025.

{% include_relative _includes/publications.md %}
<!-- {% include_relative _includes/services.md %} -->
